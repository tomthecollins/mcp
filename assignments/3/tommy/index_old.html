<html>
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Karaoke</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
	
  <script type="text/javascript" src="./lib/Tone.min_r11.js"></script>
  <script type="text/javascript" src="./lib/jquery.min.js"></script>
  <script type="text/javascript" src="./lib/Interface.js"></script>
  <script type="text/javascript" src="./lib/Logo.js"></script>
  <style type="text/css">@import url(https://fonts.googleapis.com/css?family=Roboto+Mono);</style><style type="text/css">#TonejsLogo{background-color:#000;cursor:pointer}#TonejsLogo,#TonejsLogo #Border,#TonejsLogo #Canvas,#TonejsLogo #Title{position:absolute}#TonejsLogo #TextContainer{position:absolute;width:auto;-webkit-transform:translate(-50%, 0px);-ms-transform:translate(-50%, 0px);transform:translate(-50%, 0px);left:50%;height:100%}#TonejsLogo #TextContainer #Title{position:relative;display:inline-block;font-family:Roboto Mono,monospace;color:#fff;text-align:center;height:100%;top:0;width:100%;font-weight:400}#TonejsLogo #TextContainer #Title .Closer{margin:-3%}#TonejsLogo #TextContainer #Canvas{position:absolute;height:100%;top:0;border-radius:2%;z-index:0;right:0;width:10px;background-color:#f734d7}</style>
  <script type="text/javascript" src="./lib/math_util.js"></script>
  
		<script type="text/javascript" src="./lib/fft/twiddle.js"></script>
		<script type="text/javascript" src="./lib/fft/complex.js"></script>
		<script type="text/javascript" src="./lib/fft/fftutil.js"></script>
		<script type="text/javascript" src="./lib/fft/fft.js"></script>
		
		<script type="text/javascript" src="./lib/nexusUI.js"></script>
		<script type="text/javascript" src="./lib/StartAudioContext.js"></script>
		<link rel="stylesheet" type="text/css" href="./lib/examples.css">
 </head>
 <body>
  <style type="text/css" id="hello">
   canvas {
    width: 100%;
    height: 200px;
    background-color: black;
    border-bottom-left-radius: 5px;
    border-bottom-right-radius: 5px;
   }
  </style>
  <div id="Content" class="FullScreen">
   <div id="Title">This is my project now</div>
   <div id="Explanation">
    <form action="start.php" method="post" id="varForm">
					<p><strong>Audio selection. </strong>Pick the song you want to sing along to:
					 <select id="micRecSelect">
							<option value="guitar.wav">Option 1</option>
							<option value="piano.wav">Optino 2</option>
							<option value="strings.wav">Option 3</option>
							<option value="fmpiano.mp3">Option 4</option>
							<option value="mic">Mic</option>
						</select>
					</p>
					
					<p>
						<br/>
						<button type="button" id="goToggle" onclick="go();">Start</button>
					</p>
				</form>
   </div>
			
			
			
			<script type="text/javascript">
				// Some parameters.
				var flag = true; // Start/stop flag.
				var dur_sec = 30; // Listen to the mic for a maximum of 30 sec.
				
				function go(){
					if(flag) {
						flag = false;
						document.getElementById("goToggle").innerHTML = "Stop";
						calcSimilarity(document.getElementById("micRecSelect").value);
					}
					else {
						Tone.Transport.stop();
						flag = true;
						document.getElementById("goToggle").innerHTML = "Start";
					}
				}
				
			</script>
			
			
			<div id="Explanation">
				<p>
					Here is your spectrum (fake piano file right now):
				</p>
				<div id="wavezone"></div>
				
			</div>

			<div id="Explanation">
				<p>
					Here is the target spectrum:
				</p>
				<div id="wavezone2"></div>
				
			</div>
			
			<script>
				console.log('Got to 122.')
				var canvas = $("<canvas>").appendTo("#wavezone");
				var canvas2 = $("<canvas>").appendTo("#wavezone2");
				
				function calcSimilarity(wavString){
					// For creating times at which to analyse signal.
					var nfft = 1024;
					var frame_rate = 4; // So this is 250 ms, or hop of 11025 at sampling rate of 44100.
					var tinc = 1/frame_rate;
					var toff = 0.01; // Wait 0.25 s into sound before analyzing, to avoid inharmonic onset.
					var c = 0.1; // Threshold for ignoring small-amplitude components.
					var diss = []; // Store the calculated dissonance values.
					var values4; // For plotting the incoming spectra.
					var X = [];
					var Y = [];
					
					// Argument can be used to determine whether mic input should be analyzed
					// or if we use a pre-existing recording.
					console.log('wavString:', wavString);
					
					// Need to introduce logic here, depending on whether we're really
					// listening to mic input or loading one of the example files.
					if (wavString === "mic"){
						// We are really listening to the mic.
						var mic = new Tone.UserMedia();
						var analyser = new Tone.Analyser({
							"type" : "waveform",
							"size" : nfft
						});
						mic.connect(analyser);
						var Fs = mic.context.sampleRate;
						var nsamp = Fs*dur_sec;
						// console.log('Fs:', Fs);
						// console.log('dur_sec: ', dur_sec);
						// console.log('nsamp:', nsamp);
						// This next variable holds the analysis times.
						var ts = [];
						for (i = 1; i < frame_rate*(dur_sec - nfft/Fs); i++){
								ts.push(tinc*i + toff);
						}
						
						for (i = 0; i < ts.length; i++){
							Tone.Transport.schedule(function(time){
								var values2 = analyser.getValue();
								// console.log('values2:', values2);
								var values3 = fft(values2);
								values3 = values3.slice(1, nfft/2 + 1);
								values4 = values3.map(function(x){return complex.magnitude(x);});
								// console.log('values4:', values4);
								X.push(values3);
							}, ts[i]);
						}
							
						// Show the stored info:
						Tone.Transport.schedule(function(time){
							// Do something with diss.
						}, dur_sec);
						
						Tone.Transport.start();
						mic.open();
						
					}
					else {
						// We are listening to a pre-existing audio file.
						// Fake mic input for now.
						var mic = new Tone.Player('piano.wav').toMaster();
						// 'Ground truth' or comparison audio.
						var gt = new Tone.Player(wavString).toMaster();
						mic.sync(0);
						gt.sync(0);
						var analyser = new Tone.Analyser({
							"type" : "waveform",
							"size" : nfft
						});
						var analyser2 = new Tone.Analyser({
							"type" : "waveform",
							"size" : nfft
						});
						mic.connect(analyser);
						gt.connect(analyser2);
						
						Tone.Buffer.on('load', function(){
							// Create some times at which to analyse signal.
							var Fs = gt.buffer._buffer.sampleRate;
							var nsamp = gt.buffer._buffer.length;
							dur_sec = nsamp/Fs;
							// console.log('Fs:', Fs);
							// console.log('nsamp:', nsamp);
							// console.log('dur_sec: ', dur_sec);
							// This next variable holds the analysis times.
							var ts = [];
							for (i = 1; i < frame_rate*(dur_sec - nfft/Fs); i++){
									ts.push(tinc*i + toff);
							}
							
							// Analyse the signals at these times.
							for (i = 0; i < ts.length; i++){
								Tone.Transport.schedule(function(time){
									// Mic.
									var sig_mic = analyser.getValue();
									var spec_mic = fft(sig_mic);
									var spec_rel_mic = spec_mic.slice(1, nfft/2 + 1);
									spec_mag_mic = spec_rel_mic.map(function(x){return complex.magnitude(x);});
									console.log('spec_mag_mic', spec_mag_mic);
									X.push(spec_mag_mic);
									// Gt.
									var sig_gt = analyser2.getValue();
									var spec_gt = fft(sig_gt);
									var spec_rel_gt = spec_gt.slice(1, nfft/2 + 1);
									spec_mag_gt = spec_rel_gt.map(function(x){return complex.magnitude(x);});
									console.log('spec_mag_gt', spec_mag_gt);
									Y.push(spec_mag_gt);
									
									var r = corr(X[X.length - 1], Y[Y.length - 1]);
									console.log('correlation:', r);
									
									// Pick peaks.
									// var peaks_idx_mic = pick_peaks(spec_mag_mic);
									// y is loud enough values from peak-picked values4.
									// var y = [];
									// for (i = 0; i < peaks_and_idx.length; i++){
									//	 if (peaks_and_idx[i][0] > c){
									//	 	y.push(peaks_and_idx[i]);
									//	 }
									// }
									// Y.push(y);
									// console.log('y:', y);
								}, ts[i]);
								
							}
							
							
								
							// Show the stored info:
							Tone.Transport.schedule(function(time){
								// Do something with diss.
								
							}, dur_sec);
							
							Tone.Transport.start();
							mic.start();
							gt.start();
							
						});
						
					}
					
					
					// Draw portions of the signal for funzies.
					var context = canvas.get(0).getContext("2d");
					context.canvas.width = canvas.width();
					context.canvas.height = canvas.height();
					var context2 = canvas2.get(0).getContext("2d");
					context2.canvas.width = canvas2.width();
					context2.canvas.height = canvas2.height();
					function drawLoop(){
						var canvasWidth = context.canvas.width;
						var canvasHeight = context.canvas.height;
						var canvasWidth2 = context2.canvas.width;
						var canvasHeight2 = context2.canvas.height;
						requestAnimationFrame(drawLoop);
						//draw the spectrum for mic.
						context.clearRect(0, 0, canvasWidth, canvasHeight);
						context.beginPath();
						context.lineWidth = 6;
						context.strokeStyle = "white";
						for (var i = 1, len = spec_mag_mic.length; i < len; i++){
							var val = spec_mag_mic[i] / (nfft/16);
							var y = canvasHeight*(1 - val);
							var x = canvasWidth * i / (nfft/4);
							context.lineTo(x, y);
						}
						context.stroke();
						//draw the spectrum for gt.
						context2.clearRect(0, 0, canvasWidth2, canvasHeight2);
						context2.beginPath();
						context2.lineWidth = 6;
						context2.strokeStyle = "white";
						for (var j = 1, len2 = spec_mag_gt.length; j < len2; j++){
							var val = spec_mag_gt[j] / (nfft/16);
							var y = canvasHeight2*(1 - val);
							var x = canvasWidth2 * j / (nfft/4);
							context2.lineTo(x, y);
						}
						context2.stroke();
					}
					drawLoop();
				}
			
			
			</script>
			<div id="Explanation">
				<p>
					Credits: thanks to
					Tone.js,
					fft-js
				</p>
			</div>
		</div>
 </body>
</html>
