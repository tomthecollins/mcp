<html>
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Disson-ometer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
	
  <script type="text/javascript" src="./lib/Tone.min_r11.js"></script>
  <script type="text/javascript" src="./lib/jquery.min.js"></script>
  <script type="text/javascript" src="./lib/Interface.js"></script>
  <script type="text/javascript" src="./lib/Logo.js"></script>
  <style type="text/css">@import url(https://fonts.googleapis.com/css?family=Roboto+Mono);</style><style type="text/css">#TonejsLogo{background-color:#000;cursor:pointer}#TonejsLogo,#TonejsLogo #Border,#TonejsLogo #Canvas,#TonejsLogo #Title{position:absolute}#TonejsLogo #TextContainer{position:absolute;width:auto;-webkit-transform:translate(-50%, 0px);-ms-transform:translate(-50%, 0px);transform:translate(-50%, 0px);left:50%;height:100%}#TonejsLogo #TextContainer #Title{position:relative;display:inline-block;font-family:Roboto Mono,monospace;color:#fff;text-align:center;height:100%;top:0;width:100%;font-weight:400}#TonejsLogo #TextContainer #Title .Closer{margin:-3%}#TonejsLogo #TextContainer #Canvas{position:absolute;height:100%;top:0;border-radius:2%;z-index:0;right:0;width:10px;background-color:#f734d7}</style>
  <script type="text/javascript" src="./lib/math.min.js"></script>
  <script type="text/javascript" src="./supporting/fb_256_to_82.js"></script>
		<script type="text/javascript" src="./supporting/Zfb.js"></script>
		<script type="text/javascript" src="./supporting/plomp_levelt_curve.js"></script>
		
		<script type="text/javascript" src="./lib/fft/twiddle.js"></script>
		<script type="text/javascript" src="./lib/fft/complex.js"></script>
		<script type="text/javascript" src="./lib/fft/fftutil.js"></script>
		<script type="text/javascript" src="./lib/fft/fft.js"></script>
		
		<script type="text/javascript" src="./lib/nexusUI.js"></script>
		<script type="text/javascript" src="./supporting/FileSaver.min.js"></script>
		<script type="text/javascript" src="./lib/StartAudioContext.js"></script>
		<script type="text/javascript" src="./supporting/math_util.js"></script>
		<link rel="stylesheet" type="text/css" href="./lib/examples.css">
 </head>
 <body>
  <style type="text/css" id="hello">
   canvas {
    width: 100%;
    height: 200px;
    background-color: black;
    border-bottom-left-radius: 5px;
    border-bottom-right-radius: 5px;
   }
  </style>
  <div id="Content" class="FullScreen">
   <div id="Title">Disson-ometer</div>
   <div id="Explanation">
    <p>Hello</p>
    <form action="start.php" method="post" id="varForm">
					<p><strong>Audio selection. </strong>Listen to mic input or pick a pre-existing recording:
					 <select id="micRecSelect">
							<option value="guitar.wav">Guitar</option>
							<option value="piano.wav">Piano</option>
							<option value="strings.wav">Strings</option>
							<option value="fmpiano.mp3">Organ</option>
							<option value="mic">Mic</option>
						</select>
					</p>
					
					<p>
						<br/>
						<button type="button" id="goToggle" onclick="go();">Start</button>
					</p>
				</form>
   </div>
			
			
			
			<script type="text/javascript">
			 // Some parameters.
				var flag = true; // Start/stop flag.
				var dur_sec = 30; // Listen to the mic for a maximum of 30 sec.
				
				function go(){
					if(flag) {
						flag = false;
						document.getElementById("goToggle").innerHTML = "Stop";
						calcDissonance(document.getElementById("micRecSelect").value);
					}
					else {
						Tone.Transport.stop();
						flag = true;
						document.getElementById("goToggle").innerHTML = "Start";
					}
				}
				
			</script>
			
			
			<div id="Explanation">
				<p>
					
	The inspiration for this program came from the work of
	<a href="https://www.tandfonline.com/doi/abs/10.1080/09298217808570246">William Hutchinson's and Leon Knopoff's</a>
	research on The Acoustic Component of Western Consonance, <a href="http://music.psych.cornell.edu/articles/tonality/1982K&KesslerPsychRevfromJournal.pdf
	">Carol L. Krumhansl's and Edward J. Kessler's</a> research on
	Tracing the dynamic changes in perceived tonal organization in a spatial
	representation of musical keys and a previous Music Computing student
	, <a href="http://www.tomcollinsresearch.net/mcpc/spring2017/karen/">Karen Konkoly's project, called "Musical Donuts".</a>
	
					</p>
					In this application, both pre-made sounds produced on a digital audio workstation and input from a microphone is analyzed using rules that define consonant and dissonant sounds. 

Consonant sounds are usually described as pleasant and agreeable. 
Dissonant sounds are those that cause tension and desire to be resolved.</p>
<p>

The application runs to measure dissonance and gives a real time dissonance 'score' to the sound that is being analyzed.

The higher the score the greater the dissonance.
				     
					</p>

					
					<p>This project was made possible with the help of <a href="https://github.com/Tonejs/Tone.js">Tone.js</a>, <a href="https://www.npmjs.com/package/fft-js">fft-js</a> and Professor Tom Collins. 
The demo was coded by Ashleigh Thurston as part of Dr. Collins' PSYC397 Music Computing and Psychology Course at Lehigh University.
</p>
				<p>
					The spectrum of what is playing is displayed here:
				</p>
				<div id="wavezone"></div>
				<div id="dissozone"></div>
				<div id="meterzone"></div>
				
			</div>
			
			<script>
				console.log('Got to 122.')
				var canvas = $("<canvas>").appendTo("#wavezone");
				var canvas3 = $("<canvas>").appendTo("#dissozone");
				var canvas2 = $("<canvas>").appendTo("#meterzone");
				
				function calcDissonance(wavString){
					// For creating times at which to analyse signal.
					var nfft = 1024;
					var frame_rate = 10; // So this is 100 ms, or hop of 4410 at sampling rate of 44100.
					var tinc = 1/frame_rate;
					var toff = 0.01; // Wait 0.25 s into sound before analyzing, to avoid inharmonic onset.
					var c = 0.1; // Threshold for ignoring small-amplitude components.
					var diss = []; // Store the calculated dissonance values.
					var curr_diss = 0;
					var values4; // For plotting the incoming spectra.
					var X = [];
					var Y = [];
					
					// Argument can be used to determine whether mic input should be analyzed
					// or if we use a pre-existing recording.
					console.log('wavString:', wavString);
				
					// Need to introduce logic here, depending on whether we're really
					// listening to mic input or loading one of the example files.
				if (wavString === "mic"){
					// We are really listening to the mic.
					var mic = new Tone.UserMedia();
					var analyser = new Tone.Analyser({
						"type" : "waveform",
						"size" : nfft
					});
					mic.connect(analyser);
					var Fs = mic.context.sampleRate;
					var nsamp = Fs*dur_sec;
					// console.log('Fs:', Fs);
					// console.log('dur_sec: ', dur_sec);
					// console.log('nsamp:', nsamp);
					// This next variable holds the analysis times.
					var ts = [];
					for (i = 1; i < frame_rate*(dur_sec - nfft/Fs); i++){
							ts.push(tinc*i + toff);
					}
					
					for (i = 0; i < ts.length; i++){
						Tone.Transport.schedule(function(time){
							var values2 = analyser.getValue();
							// console.log('values2:', values2);
							// values2 = [].slice.call(values2);	
							// console.log('values2 post slice call:', values2);
							var values3 = fft(values2);
							values3 = values3.slice(1, nfft/2 + 1);
							values4 = values3.map(function(x){return complex.magnitude(x);});
							// console.log('values4:', values4);
							X.push(values3);
						}, ts[i]);
					}
						
					// Show the stored info:
					Tone.Transport.schedule(function(time){
						// Do something with diss.
					}, dur_sec);
					
					Tone.Transport.start();
     mic.open();
					
				}
				else {
					var diss_meter = new Tone.Meter();
					var meter = new Tone.Meter();
					// We are listening to a pre-existing audio file.
					var mic = new Tone.Player(wavString).connect(meter).toMaster();
					// var mic = new Tone.Player('./../20171127/ground_truth/' + idxStr + '.wav').toMaster();
					mic.sync(0);
					var analyser = new Tone.Analyser({
						"type" : "waveform",
						"size" : nfft
					});
					mic.connect(analyser);
					
					Tone.Buffer.on('load', function(){
						// Create some times at which to analyse signal.
						var Fs = mic.buffer._buffer.sampleRate;
						var fspace = Fs/2/nfft;
						console.log('fspace:', fspace);
						var nsamp = mic.buffer._buffer.length;
						dur_sec = nsamp/Fs;
						// console.log('Fs:', Fs);
						// console.log('nsamp:', nsamp);
						// console.log('dur_sec: ', dur_sec);
						// This next variable holds the analysis times.
						var ts = [];
						for (i = 1; i < frame_rate*(dur_sec - nfft/Fs); i++){
								ts.push(tinc*i + toff);
						}
						
						// Analyse the signal at these times.
						for (i = 0; i < ts.length; i++){
							Tone.Transport.schedule(function(time){
								var values2 = analyser.getValue();
								// console.log('values2:', values2);
								// values2 = [].slice.call(values2);	
								// console.log('values2 post slice call:', values2);
								var values3 = fft(values2);
								values3 = values3.slice(1, nfft/2 + 1);
								values4 = values3.map(function(x){return complex.magnitude(x);});
								// console.log('values4:', values4);
								X.push(values4);
								
								// Pick peaks.
								var peaks_and_idx = pick_peaks(values4);
								
								// y is loud enough values from peak-picked values4.
								var y = [];
								for (i = 0; i < peaks_and_idx.length; i++){
									if (peaks_and_idx[i][0] > c){
										y.push(peaks_and_idx[i]);
									}
								}
								Y.push(y);
								// console.log('y:', y);
								
								// Calculate contribution to sensory dissonance.
								var diss_contrib = sensory_dissonance(y, fspace);
								// console.log('diss_contrib:', diss_contrib);
								if (diss_contrib.length > 0){
								 curr_diss = diss_contrib.map(function(d){
									return d.diss;
								})
								.reduce(function(a, b){
									return a + b;
								});
								}
								
								console.log('curr_diss:', curr_diss);
								diss.push(curr_diss);
								// diss_meter
								
							}, ts[i]);
						}
							
						// Testing the meter:
						//Tone.Transport.schedule(function(time){
						//	meter.toMaster();
						//	console.log('meter', meter.getLevel());
						//}, 2);
						
						Tone.Transport.start();
						mic.start();
						
					});
					
				}
				
				
				// Draw portions of the signal for funzies.
				var context = canvas.get(0).getContext("2d");
				context.canvas.width = canvas.width();
				context.canvas.height = canvas.height();
				function drawLoop(){
					var canvasWidth = context.canvas.width;
					var canvasHeight = context.canvas.height;
					requestAnimationFrame(drawLoop);
					//draw the waveform
					context.clearRect(0, 0, canvasWidth, canvasHeight);
					// var values = analyser.analyse();
					context.beginPath();
					//context.lineJoin = "round";
					context.lineWidth = 6;
					context.strokeStyle = "white";
					if (values4 !== undefined){
						for (var i = 1, len = values4.length; i < len; i++){
							var val = values4[i] / (nfft/16);
							var y = canvasHeight*(1 - val);
							var x = canvasWidth * i / (nfft/4);
							context.lineTo(x, y);
						}
						context.stroke();
					}
					
				}
				drawLoop();
				
				console.log('We got to the meter!')
				
				
				var meterContext = canvas2.get(0).getContext("2d");
				var meterContext3 = canvas3.get(0).getContext("2d");
				var meterGraident;
				function drawMeter(){
					// console.log('Meter', meter)
					var level = meter.getLevel();
					level = Tone.dbToGain(level); //scale it between 0 - 1
					// var level = Math.random();
					meterContext.clearRect(0, 0, canvasWidth, canvasHeight);
					meterContext.fillStyle = meterGraident;
					meterContext.fillRect(0, 0, canvasWidth, canvasHeight);
					meterContext.fillStyle = "white";
					meterContext.fillRect(canvasWidth * level, 0, canvasWidth, canvasHeight);
					
					meterContext3.clearRect(0, 0, canvasWidth, canvasHeight);
					meterContext3.fillStyle = meterGraident;
					meterContext3.fillRect(0, 0, canvasWidth, canvasHeight);
					meterContext3.fillStyle = "white";
					meterContext3.fillRect(canvasWidth * curr_diss/7000, 0, canvasWidth, canvasHeight);
				}
				//size the canvase
				var canvasWidth, canvasHeight;
				function sizeCanvases(){
					canvasWidth = $("#meterzone").width();
					canvasHeight = $("#meterzone").height();
					meterContext.canvas.width = canvasWidth;
					meterContext.canvas.height = canvasHeight;
					meterContext3.canvas.width = canvasWidth;
					meterContext3.canvas.height = canvasHeight;
					//make the gradient
					meterGraident = meterContext.createLinearGradient(0, 0, canvasWidth, canvasHeight);
					meterGraident.addColorStop(0, "#BFFF02");
					meterGraident.addColorStop(0.8, "#02FF24");
					meterGraident.addColorStop(1, "#FF0202");
				}
				sizeCanvases();
				$(window).resize(sizeCanvases);
				function loop(){
					requestAnimationFrame(loop);
					//draw the meter level
					drawMeter();
				}
				loop();
				
				
				
				
				
				
				
			}
      
			
			
		</script>
  <div id="Explanation">
			<p>
				Credits: thanks to
				Tone.js,
				fft-js
			</p>
		</div>
		</div>
 </body>
</html>
